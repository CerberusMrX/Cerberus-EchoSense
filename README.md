# Cerberus EchoSense
**Adaptive Multi-Modal AI-Powered Motion Detection System**

<div align="center">

![Version](https://img.shields.io/badge/version-2.0-blue)
![Python](https://img.shields.io/badge/python-3.9+-green)
![License](https://img.shields.io/badge/license-MIT-orange)

*Advanced Detection System with Camera Vision, WiFi Sensing, and Intelligent Sensor Fusion*

</div>

---

## ğŸ¯ Overview

Cerberus EchoSense is a **modular detection platform** that adapts to whatever hardware you have available. From simple webcam-based object detection to advanced WiFi CSI sensing, the system provides comprehensive motion tracking with intelligent handoff between sensors.

### Key Features

âœ¨ **Flexible Hardware Support**
- ğŸ¥ **Camera Only** - YOLO object detection + pose estimation
- ğŸ“¡ **ESP8266** - Basic WiFi RSSI motion detection  
- ğŸ”¬ **ESP32** - Advanced CSI-based ML classification
- ğŸ“¶ **WiFi Adapter** - Monitor mode packet capture
- ğŸ¯ **Hybrid** - Camera + WiFi with intelligent handoff

ğŸ¤– **AI/ML Powered**
- YOLOv8 object detection (real-time)
- MediaPipe pose estimation (17 keypoints)
- LSTM-based CSI motion classifier
- Activity recognition (walking, standing, sitting, running)
- Multi-object tracking with persistent IDs

ğŸŒ **Advanced Capabilities**
- **Intelligent Handoff**: Track objects from camera â†’ WiFi when exiting frame
- **Through-Wall Detection**: WiFi sensing works through obstacles
- **24/7 Coverage**: Camera for precision, WiFi for continuous presence
- **Real-time WebSocket Streaming**: Live updates to browser dashboard

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/your-username/cerberus-echosense
cd cerberus-echosense

# Run setup wizard (interactive)
python setup_wizard.py
```

The wizard will:
1. Detect available hardware (camera, WiFi adapters)
2. Prompt you to select mode (Camera/ESP8266/ESP32/WiFi/Hybrid)
3. Install required dependencies
4. Download ML models
5. Generate configuration file

### Running the System

```bash
# Terminal 1: Backend
cd backend
python server.py

# Terminal 2: Frontend
cd frontend
npm install  # First time only
npm run dev

# Open browser
# http://localhost:5173
```

---

## ğŸ“– Hardware Modes Explained

| Mode | Hardware | Use Case | Setup Time |
|------|----------|----------|------------|
| **Camera Only** | USB Webcam | Indoor object detection, pose tracking | 5 min |
| **ESP8266 RSSI** | 2x ESP8266 | Through-wall motion, presence detection | 15 min |
| **ESP32 CSI** | 2x ESP32 | Research-grade WiFi sensing, ML classification | 30 min |
| **WiFi Adapter** | Monitor-capable adapter | No ESP needed, ambient WiFi analysis | 10 min |
| **Hybrid** | Camera + any WiFi | Complete coverage, handoff tracking | 20 min |

### Mode Selection Guide

**Choose Camera Only if:**
- You have a webcam but no ESP boards
- You need precise bounding boxes and pose estimation
- You only care about in-frame detection

**Choose ESP8266/ESP32 if:**
- You want through-wall/obstacle detection
- You need presence sensing without cameras
- Privacy is a concern (no video capture)

**Choose WiFi Adapter if:**
- You don't have ESP boards
- You have a monitor-capable WiFi adapter
- You're on Linux with root access

**Choose Hybrid if:**
- You want the best of both worlds
- You need seamless tracking as objects exit camera FOV
- You want 24/7 coverage (camera precision + WiFi continuity)

See **[HARDWARE_GUIDE.md](HARDWARE_GUIDE.md)** for detailed setup instructions!

---

## ğŸ—ï¸ System Architecture

```mermaid
graph TB
    subgraph Hardware[Hardware Layer - Choose What You Have]
        CAM[Camera]
        ESP8266[ESP8266 x2]
        ESP32[ESP32 x2]
        WIFI[WiFi Adapter]
    end
    
    subgraph Backend[Adaptive Backend]
        CONFIG[Config Manager]
        ML[ML Engine]
        FUSION[Sensor Fusion]
    end
    
    subgraph Models[AI Models - Load on Demand]
        YOLO[YOLOv8]
        POSE[MediaPipe]
        CSI_ML[CNN Classifier]
    end
    
    subgraph Frontend[Web Dashboard]
        REACT[React UI]
        RADAR[3D Radar]
        CAMERA_VIEW[Camera Feed]
    end
    
    CAM -.-> CONFIG
    ESP8266 -.-> CONFIG
    ESP32 -.-> CONFIG
    WIFI -.-> CONFIG
    
    CONFIG --> ML
    ML --> YOLO
    ML --> POSE
    ML --> CSI_ML
    
    ML --> FUSION
    FUSION --> WS[WebSocket]
    WS --> REACT
    REACT --> RADAR
    REACT --> CAMERA_VIEW
```

---

## ğŸ® Features by Mode

### Camera Mode Features
- âœ… Real-time object detection (80+ classes)
- âœ… Person tracking with bounding boxes
- âœ… Pose estimation (17 skeletal keypoints)
- âœ… Activity recognition (walking, standing, sitting)
- âœ… Multi-person tracking with unique IDs
- âœ… Confidence scoring
- âŒ Through-wall detection
- âŒ Out-of-frame tracking

### WiFi Mode Features (ESP8266/ESP32/Adapter)
- âœ… Through-wall/obstacle motion detection
- âœ… Presence sensing (no visual data)
- âœ… Privacy-preserving (no camera)
- âœ… Works in darkness
- âœ… ML-based classification (ESP32)
- âŒ Precise localization
- âŒ Pose/appearance information

### Hybrid Mode Features (Camera + WiFi)
- âœ… **All camera features**
- âœ… **All WiFi features**
- âœ… **Intelligent handoff** when exiting camera FOV
- âœ… **Persistent tracking IDs** across modalities
- âœ… **24/7 coverage** (indoor + outdoor)
- âœ… **Best accuracy** with sensor fusion

---

## ğŸŒŠ Detection Flow (Hybrid Mode)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Person Enters Room                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Camera Detection   â”‚ â† YOLO + Pose
              â”‚  Source: CAMERA     â”‚
              â”‚  ID: #1             â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Person exits frame  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Handoff Delay      â”‚ â† 500ms configurable
              â”‚  (500ms)            â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  WiFi Detection     â”‚ â† CSI/RSSI variance
              â”‚  Source: WIFI       â”‚
              â”‚  ID: #1 (same!)     â”‚
              â”‚  Out of Frame: âœ“    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Person re-enters    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Camera Re-acquire  â”‚ â† ID preserved
              â”‚  Source: CAMERA     â”‚
              â”‚  ID: #1             â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Web Dashboard

The React-based dashboard provides:

### Main View
- **3D Radar Visualization** - Animated radar sweep with motion blips
- **Spectral Grid** - CSI subcarrier heatmap (ESP32 mode)
- **Pose Skeleton** - Real-time stick figure (Camera mode)
- **Detection Stats** - RSSI, variance, confidence metrics

### Camera Feed View (Camera/Hybrid modes)
- **Live Video Stream** - Real-time camera feed
- **Bounding Boxes** - Green (camera) / Orange (WiFi handoff)
- **Tracking IDs** - Persistent object identifiers
- **Pose Overlay** - Skeletal keypoints on detected persons

### Activity Timeline
- **Event History** - Timestamped detection events
- **Mode Indicators** - Camera/WiFi/Fusion source markers
- **Confidence Graphs** - Detection confidence over time

---

## âš™ï¸ Configuration

Edit `config.yaml` after running setup wizard:

```yaml
hardware:
  mode: "hybrid"  # auto, camera_only, esp8266, esp32, wifi_adapter, hybrid
  
  camera:
    enabled: true
    device: 0
    resolution: [640, 480]
    fps: 30
  
  esp32:
    enabled: true
    udp_port: 8889

detection:
  yolo:
    model: "yolov8n.pt"
    confidence: 0.5
    device: "cuda"  # cpu, cuda, mps
  
  csi:
    use_ml_classifier: true
    model_path: "models/csi_lstm.h5"

fusion:
  camera_priority: true
  handoff_delay_ms: 500
  tracking_timeout_s: 5
```

---

## ğŸ§ª Advanced: Training Custom CSI Models

For ESP32 CSI mode, you can train custom activity classifiers:

```bash
# 1. Collect labeled data
python backend/collect_csi_data.py --label walking --duration 120
python backend/collect_csi_data.py --label sitting --duration 120
python backend/collect_csi_data.py --label standing --duration 120

# 2. Train LSTM model
python backend/train_csi_model.py \
    --data data/csi_samples/ \
    --epochs 50 \
    --batch-size 32

# 3. Model saved to backend/models/csi_lstm.h5
```

---

## ğŸ”¬ Technical Details

### Camera Vision Pipeline
- **YOLO**: YOLOv8n (nano) for real-time detection @ 30+ FPS
- **Pose**: MediaPipe Pose (BlazePose) - 17 keypoints
- **Tracking**: Centroid-based ID assignment with IoU matching

### WiFi Sensing Methods
- **RSSI (ESP8266)**: Variance analysis on rolling window
- **CSI (ESP32)**: 64 subcarrier amplitude/phase extraction
- **Monitor Mode**: Ambient packet RSSI analysis

### Sensor Fusion Algorithm
1. If camera detects â†’ use camera (high confidence)
2. If camera loses object â†’ start handoff timer
3. After delay â†’ switch to WiFi if motion detected
4. WiFi continues tracking with "out of frame" flag
5. Camera re-acquires â†’ resume camera tracking (same ID)

---

## ğŸ“ Project Structure

```
cerberus-echosense/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.py           # Main FastAPI backend
â”‚   â”œâ”€â”€ ml_engine.py        # Modular detection engine
â”‚   â”œâ”€â”€ wifi_monitor.py     # WiFi adapter capture script
â”‚   â”œâ”€â”€ models/             # ML model storage
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ firmware/
â”‚   â”œâ”€â”€ tx_main/            # ESP8266 transmitter
â”‚   â”œâ”€â”€ rx_main/            # ESP8266 receiver
â”‚   â”œâ”€â”€ esp32_csi_tx/       # ESP32 CSI transmitter
â”‚   â””â”€â”€ esp32_csi_rx/       # ESP32 CSI receiver
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ Radar.jsx
â”‚   â”‚       â””â”€â”€ CameraView.jsx
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ config.yaml             # System configuration
â”œâ”€â”€ setup_wizard.py         # Interactive setup
â”œâ”€â”€ README.md
â””â”€â”€ HARDWARE_GUIDE.md       # Detailed hardware setup
```

---

## ğŸ¤ Contributing

Contributions welcome! Areas of interest:
- Additional ML models (pose classification, gesture recognition)
- Support for more hardware (ESP32-C3, Raspberry Pi Pico W)
- Frontend enhancements (charts, alerts, multi-camera)
- CSI processing improvements

---

## ğŸ“„ License

MIT License - see LICENSE file

---

## ğŸ™ Acknowledgments

- **YOLOv8** - Ultralytics
- **MediaPipe** - Google
- **ESP32-CSI-Tool** - Steven Hernandez
- **React Three Fiber** - Poimandres

---

## ğŸ“ Support

- **Issues**: Open an issue on GitHub
- **Discussions**: Start a discussion for questions
- **Email**: sudeepawanigarathne09@gmail.com

---

**Built with â¤ï¸ by Sudeepa Wanigarathna**

*Transforming commodity hardware into intelligent sensing systems*
